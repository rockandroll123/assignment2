{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import os\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from sklearn import preprocessing\n",
    "from autokeras.image.image_supervised import load_image_dataset\n",
    "\n",
    "from autokeras.image.image_supervised import ImageClassifier\n",
    "from autokeras.image.image_supervised import load_image_dataset\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications import vgg16, inception_v3, resnet50, mobilenet\n",
    " \n",
    "\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows',5)\n",
    "pd.set_option('precision',3)\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>.container { width:100% !important;}</style>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_images=os.listdir(\"./data/box/images\")\n",
    "#print(len(all_train_images))\n",
    "labels=[x.split(\"_\")[0] for x in all_train_images]\n",
    "labels_my=[int(x.split(\"_\")[1].split('.png')[0]) for x in all_train_images]\n",
    "labels_my\n",
    "\n",
    "# trail all, delete\n",
    "\n",
    "filt=pd.DataFrame({'image':all_train_images,'label':labels,'num':labels_my})\n",
    "filt\n",
    "all_train_images=filt['image'].tolist()\n",
    "labels=filt['label'].tolist()\n",
    "\n",
    "with open('train_label.csv', 'w') as train_csv:\n",
    "    fieldnames = ['File Name', 'Label']\n",
    "    writer = csv.DictWriter(train_csv, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(all_train_images)):\n",
    "        writer.writerow({'File Name': all_train_images[i], 'Label':labels[i]})\n",
    "    train_csv.close()\n",
    "\n",
    "x_train, y_train = load_image_dataset(csv_file_path=\"train_label.csv\",\n",
    "                                      images_path=\"./data/box/images\")\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "\n",
    "filt = pd.read_csv('./val/val_annotations.txt', sep=\"\\t\", header=None)\n",
    "filt.columns=['image','label','a','b','c','d']\n",
    "filt['image']=filt['image'].apply(lambda x: x.split('.')[0]+'.png')\n",
    "\n",
    "all_train_images=filt['image'].tolist()\n",
    "labels=filt['label'].tolist()\n",
    "\n",
    "with open('valid_label.csv', 'w') as train_csv:\n",
    "    fieldnames = ['File Name', 'Label']\n",
    "    writer = csv.DictWriter(train_csv, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(all_train_images)):\n",
    "        writer.writerow({'File Name': all_train_images[i], 'Label':labels[i]})\n",
    "    train_csv.close()\n",
    "    \n",
    "x_valid, y_valid = load_image_dataset(csv_file_path=\"valid_label.csv\",\n",
    "                                      images_path=\"./data/val/box/images\")\n",
    "print(x_valid.shape)\n",
    "print(y_valid.shape)\n",
    "\n",
    "\n",
    "all_train_images=os.listdir(\"./data/test/box/images\")\n",
    "labels=['unknow' for x in all_train_images]\n",
    "labels_my=['unknow' for x in all_train_images]\n",
    "\n",
    "\n",
    "filt=pd.DataFrame({'image':all_train_images,'label':labels,'num':labels_my})\n",
    "all_train_images=filt['image'].tolist()\n",
    "labels=filt['label'].tolist()\n",
    "import csv\n",
    "with open('test_label.csv', 'w') as train_csv:\n",
    "    fieldnames = ['File Name', 'Label']\n",
    "    writer = csv.DictWriter(train_csv, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(all_train_images)):\n",
    "        writer.writerow({'File Name': all_train_images[i], 'Label':labels[i]})\n",
    "    train_csv.close()\n",
    "    \n",
    "x_test, y_test = load_image_dataset(csv_file_path=\"test_label.csv\",\n",
    "                                      images_path=\"./data/test/box/images\")\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype(\"float\") / 255.0\n",
    "x_valid = x_valid.astype(\"float\") / 255.0\n",
    "x_test = x_test.astype(\"float\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train)\n",
    "y_train1=le.transform(y_train) \n",
    "y_train2= keras.utils.to_categorical(y_train1, 200)\n",
    "y_valid1=le.transform(y_valid) \n",
    "y_valid2= keras.utils.to_categorical(y_valid1, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TIMES = [\n",
    "    60 * 60 *0.1, # 6 hour\n",
    "    60 * 60 * 2, # 2 hours\n",
    "    60 * 60 * 3, # 3 hours\n",
    "    60 * 60 * 4, # 4 hours\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "for seconds in TRAINING_TIMES:\n",
    "    print(\"[INFO] training model for {} seconds max...\".format(seconds))\n",
    "    clf = ImageClassifier(verbose=True,augment=True, searcher_args={'trainer_args':{'max_no_improvement_num':4}})\n",
    "    clf.fit(x_train, y_train, time_limit=seconds)\n",
    "    fitted=clf.final_fit(x_train, y_train,x_valid, y_valid, retrain=True)\n",
    "    print(clf.summary())\n",
    "    # evaluate the Auto-Keras model\n",
    "    score_train = clf.evaluate(x_train, y_train)\n",
    "    score_valid = clf.evaluate(x_valid, y_valid)\n",
    "    y_predict = clf.predict(x_test)\n",
    "    \n",
    "    print(score_train,score_valid)\n",
    "    #results.append([clf.copy(),seconds,score_train,score_valid,score_test])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = clf.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', scores[0])\n",
    "print('Train accuracy:', scores[1])\n",
    "scores = clf.evaluate(x_valid, y_valid, verbose=1)\n",
    "print('Validation loss:', scores[0])\n",
    "print('Validation accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict_p1=clf.predict(x_test)\n",
    "y_predict_p1_1= [np.argmax(y, axis=None, out=None) for y in y_predict_p1]\n",
    "y_predict_p1_2=le.inverse_transform(y_predict_p1_1)\n",
    "y_predict_p1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('y_predicted_p2.csv', 'w') as train_csv:\n",
    "    fieldnames = ['Label']\n",
    "    writer = csv.DictWriter(train_csv, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(len(y_predict_p1_2)):\n",
    "        writer.writerow({ 'Label':y_predict_p1_2[i]})\n",
    "    train_csv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict=history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = fitted.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
